# 26. 커스텀 스크래핑 (Custom Scraping) - 웹상의 모든 데이터를 지식관리가 가능해!?

> **"Ctrl+C, Ctrl+V는 이제 그만. AI에게 '만들어줘'라고 말하세요."**

## 1. 🎯 개념 및 필요성 (Concept)

### 🧐 이게 뭐죠?
웹사이트에 있는 정보(뉴스, 가격, 댓글, 공지사항 등)를 자동으로 수집하는 **'로봇(Bot)'**을 만드는 기술입니다. 우리는 복잡한 코딩 대신 AI에게 "이거 가져와"라고 시키면 AI가 알아서 로봇을 만들어줍니다.

### 💡 왜 배워야 하죠?
- **노가다 해방**: 매일 아침 경쟁사 가격 확인, 뉴스 검색... 1시간 걸리던 일을 버튼 한 번으로 끝냅니다.
- **대량 수집**: 사람 손으로 100개 복사하면 손가락 아프지만, 로봇은 100만 개도 군말 없이 가져옵니다.
- 그렇지만 우리는 저작권 및 시스템 침해 방지, 회사/개인정보의 중요성에 대해서도 배워야하는 것을 잊지 않으셔야 합니다.

---

## 2. 🚀 이용 방법 (How-to)

이 스킬은 조금 특별합니다. 명령어가 아니라 **Claude Code에게 말(채팅)로** 시킵니다.

### 1️⃣ Claude Code에게 말 걸기
터미널에서 `claude` 엔터 치고 대화를 시작하세요.

### 2️⃣ 요청하기 (마법의 주문)
```text
"네이버 증권에서 [삼성전자] 주가랑 관련 뉴스 제목 5개만 크롤링하는 코드 짜줘."
```
또는
```text
"이 사이트(URL)에 있는 채용 공고 리스트를 엑셀로 저장하고 싶어. 스크래핑 해줘."
```

### 3️⃣ AI의 질문에 대답하기
AI가 똑똑해서 더 정확히 하려고 물어볼 겁니다.
- *"뉴스 제목만 가져올까요, 내용도 가져올까요?"*
- *"몇 페이지까지 긁을까요?"*

> 원하는 대로 대답해주면, AI가 **즉석에서 프로그램을 코딩해서 실행**해줍니다!<br>
> **자세하게 구체적으로 요청하는 만큼** AI가 더 정확하게 데이터를 수집할 수 있습니다.
> 물론 알아서 해달라고 하면 해주기는 합니다. 

---

## 3. 🤖 프로세스 이해하기 (Process)

1. **분석 (Explore)**: AI가 먼저 사이트에 가서 구조를 봅니다. "아, 제목은 여기 있고 가격은 저기 숨어있네."
2. **제작 (Generate)**: 정보를 쏙쏙 빼내는 맞춤형 도구(Python 코드)를 짭니다.
3. **수집 (Collect)**: 도구를 실행해서 데이터를 긁어모아 파일(`csv`, `md`)로 저장합니다.

### 🏭 지식 관리 시스템에서의 위치
- **실행 위치**: `30-collected` 폴더로 이동해서 실행하세요. (`cd 30-collected`)
- **이동**: 프로젝트용 데이터는 `10-working/{프로젝트}/` 폴더로 옮겨 관리합니다.
- **역할**: 웹상의 "휘발성 정보"를 내 컴퓨터의 "지식 자산"으로 만듭니다.

---

## 4. 💼 직무별 활용 사례 (Use Case)

### 🏪 전략팀 담당자 - "임원 트렌드 보고"
- **상황**: 매일 혹은 매주 산업 트렌드를 분석하고 보고서를 작성하고 보고서나 제출해야 함.
- **후**: "IT뉴스 어제일자 기사 분석해줘" → Claude Code에게 "우리회사 제품과 관련하여 영향도를 분석하고 3단계로 분류해줘" → **사업 방향 수립 및 개선**.

### 📢 홍보/PR 담당자 - "네티즌 여론 조사관"
- **상황**: 우리 회사 신제품에 대한 커뮤니티, 블로그 반응을 모아야 함.
- **전**: 각종 사이트 돌아다니며 검색하고 캡처하고 엑셀에 정리.
- **후**: "주요 커뮤니티에서 [제품명] 검색해서 게시글 제목이랑 조회수 분석해" → **여론 분석 리포트 자동 생성**.

### 🛍️ 쇼핑몰 MD - "최저가 탐지기"
- **상황**: 경쟁사 A, B, C가 가격을 내렸는지 매일 확인해야 함.
- **전**: 즐겨찾기 해둔 사이트 50개 매일 아침마다 클릭하고 정리해야 함.
- **후**: "경쟁사 베스트 상품 50개 가격 긁어서 분석해줘" → **경쟁사 상품 분석현황 자동 구축**.

### 💼 HR 채용 담당자 - "인재 발굴단"
- **상황**: 채용 사이트에서 특정 기술을 가진 개발자를 찾아야 함.
- **전**: 키워드 검색 후 무한 스크롤 내리며 프로필 확인.
- **후**: "채용 사이트에서 'Python', 'AI' 키워드 있는 우리회사에 적합한 인재를 분석해줘" → **인재 풀(Pool) 자동 구축**.

### 🏪 소상공인/자영업자 - "상품 리뷰 관리"
- **상황**: 커머스 플랫폼에 달린 우리 제품 리뷰를 모아서 분석하고 싶음.
- **후**: "커머스 플랫폼 달린 우리 제품 리뷰 최신순으로 100개 분석해" → Claude Code에게 "긍정/부정 리뷰 분류하고, 불만 사항 핵심 3가지만 알려줘" → **서비스 개선**.

---

## 5. 🍯 꿀팁: Claude Code에게 뭐라고 질문하나요? (Prompt)

스크래핑을 시킬 때는 **"육하원칙"**을 생각하세요.

> **"누가":** (생략 가능, Claude Code가 함)
> **"어디서":** [URL 주소], [메뉴 / 탭 / 영역 / 위치] 에서
> **"무엇을":** [상품명, 가격, 리뷰 수] 데이터를
> **"어떻게":** [엑셀 파일, 마크다운, txt]로 저장해줘.
> **"왜":** (생략 가능)
> **"언제":** (생략 가능)

**실전 프롬프트 예시:**
`"https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=105 여기 있는 '헤드라인 뉴스' 제목이랑 링크만 10개 뽑아서 마크다운 표로 만들어줘."`

**만든것으로 끝이 아닙니다. 써먹어야죠!**
> 원하는 데이터 수집이 끝났으면, Claude Code에게 "이 스킬로 만들어달라고 하세요.<br>
> " 스킬로 만들어야 AI가 직접 도구로 활용하고 우리가 원하는 분석까지 진행할 수 있습니다. 

---

**⚠️ 주의사항**: 
웹 스크래핑은 강력하지만 책임이 따릅니다. 
1. **`robots.txt` 준수**: AI가 "이 사이트는 수집하면 안 돼요"라고 경고하면 멈추세요.
2. **서버 부하 주의**: 너무 빠르게 많이 긁으면 사이트가 아파하거나 내 IP를 차단할 수 있습니다. (AI가 알아서 조절하지만, 욕심은 금물!)
3. **저작권을 존중하세요**: 뉴스, 블로그, 리뷰 등 모든 정보를 수집하는 것은 저작권이므로 주의하세요.